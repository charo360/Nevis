import OpenAI from 'openai';

// Load environment variables
require('dotenv').config({ path: '.env.local' });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

async function checkOpenAIUsage() {
  console.log('ğŸ” Checking OpenAI API Usage and Assistant Status...\n');

  try {
    // Check if we can access the API
    console.log('ğŸ“¡ **API Connection Test:**');
    const models = await openai.models.list();
    console.log(`âœ… Connected to OpenAI API successfully`);
    console.log(`ğŸ“Š Available models: ${models.data.length} models found\n`);

    // Check assistant status
    console.log('ğŸ¤– **Assistant Status Check:**');
    const assistantIds = {
      food: process.env.OPENAI_ASSISTANT_FOOD,
      retail: process.env.OPENAI_ASSISTANT_RETAIL,
      finance: process.env.OPENAI_ASSISTANT_FINANCE,
      service: process.env.OPENAI_ASSISTANT_SERVICE,
    };

    for (const [type, id] of Object.entries(assistantIds)) {
      if (id) {
        try {
          const assistant = await openai.beta.assistants.retrieve(id);
          console.log(`âœ… ${type.toUpperCase()} Assistant (${id}): Active`);
          console.log(`   Model: ${assistant.model}`);
          console.log(`   Name: ${assistant.name}`);
          console.log(`   Instructions Length: ${assistant.instructions?.length || 0} chars`);
        } catch (error) {
          console.log(`âŒ ${type.toUpperCase()} Assistant (${id}): Error - ${error}`);
        }
      } else {
        console.log(`âš ï¸ ${type.toUpperCase()} Assistant: No ID configured`);
      }
    }

    console.log('\nğŸ’° **Token Usage Information:**');
    console.log('â„¹ï¸ OpenAI API does not provide real-time usage data via API');
    console.log('â„¹ï¸ To check token usage and billing:');
    console.log('   1. Visit: https://platform.openai.com/usage');
    console.log('   2. Check your current billing period usage');
    console.log('   3. Monitor costs in the billing dashboard');

    console.log('\nğŸ”§ **Assistant API Pricing (as of 2024):**');
    console.log('   â€¢ GPT-4 Turbo: $0.01/1K input tokens, $0.03/1K output tokens');
    console.log('   â€¢ GPT-4: $0.03/1K input tokens, $0.06/1K output tokens');
    console.log('   â€¢ Assistant API adds minimal overhead for thread management');

    console.log('\nğŸ“ˆ **Usage Optimization Tips:**');
    console.log('   â€¢ Assistants reuse context efficiently across conversations');
    console.log('   â€¢ Thread management reduces redundant context passing');
    console.log('   â€¢ Specialized assistants generate more targeted content');
    console.log('   â€¢ Consider using GPT-4 Turbo for cost optimization');

    // Test a simple assistant call to see actual token usage
    console.log('\nğŸ§ª **Test Assistant Call:**');
    const foodAssistantId = process.env.OPENAI_ASSISTANT_FOOD;
    if (foodAssistantId) {
      try {
        const thread = await openai.beta.threads.create();
        console.log(`ğŸ“ Created test thread: ${thread.id}`);

        const message = await openai.beta.threads.messages.create(thread.id, {
          role: 'user',
          content: 'Generate a simple 2-word headline for fish cookies.'
        });

        const run = await openai.beta.threads.runs.create(thread.id, {
          assistant_id: foodAssistantId
        });

        // Wait for completion
        let runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
        let attempts = 0;
        while (runStatus.status === 'queued' || runStatus.status === 'in_progress') {
          if (attempts++ > 30) break; // 30 second timeout
          await new Promise(resolve => setTimeout(resolve, 1000));
          runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
        }

        if (runStatus.status === 'completed') {
          const messages = await openai.beta.threads.messages.list(thread.id);
          const response = messages.data[0];
          console.log(`âœ… Test successful! Response: "${response.content[0].text?.value}"`);
          
          // Check if usage info is available
          if (runStatus.usage) {
            console.log(`ğŸ“Š Token Usage for this call:`);
            console.log(`   Input tokens: ${runStatus.usage.prompt_tokens}`);
            console.log(`   Output tokens: ${runStatus.usage.completion_tokens}`);
            console.log(`   Total tokens: ${runStatus.usage.total_tokens}`);
          } else {
            console.log(`â„¹ï¸ Token usage data not available in response`);
          }
        } else {
          console.log(`âŒ Test failed with status: ${runStatus.status}`);
        }

        // Clean up
        await openai.beta.threads.del(thread.id);
        console.log(`ğŸ—‘ï¸ Cleaned up test thread`);

      } catch (error) {
        console.log(`âŒ Test assistant call failed: ${error}`);
      }
    }

  } catch (error) {
    console.error('âŒ Error checking OpenAI usage:', error);
    process.exit(1);
  }
}

checkOpenAIUsage();
